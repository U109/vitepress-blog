## 什么是RabbitMQ？

`RabbitMQ`是一款开源的，`Erlang`编写的，基于`AMQP`协议的消息中间件

## RabbitMQ的使用场景

（1）服务间异步通信

（2）顺序消费

（3）定时任务

（4）请求削峰

## RabbitMQ基本概念

* **Broker**： 简单来说就是消息队列服务器实体
* **Exchange**： 消息交换机，它指定消息按什么规则，路由到哪个队列
* **Queue**： 消息队列载体，每个消息都会被投入到一个或多个队列
* **Binding**： 绑定，它的作用就是把`exchange`和`queue`按照路由规则绑定起来
* **Routing Key**： 路由关键字，`exchange`根据这个关键字进行消息投递
* **VHost**： `vhost` 可以理解为虚拟 `broker` ，即 `mini-RabbitMQ server`。其内部均含有独立的 `queue`、`exchange` 和 `binding` 等，但最最重要的是，其拥有独立的权限系统，
可以做到 `vhost` 范围的用户控制。当然，从 `RabbitMQ` 的全局角度，`vhost` 可以作为不同权限隔离的手段（一个典型的例子就是不同的应用可以跑在不同的 `vhost` 中）。
* **Producer**： 消息生产者，就是投递消息的程序
* **Consumer**： 消息消费者，就是接受消息的程序
* **Channel**： 消息通道，在客户端的每个连接里，可建立多个`channel`，每个`channel`代表一个会话任务

由`Exchange`、`Queue`、`RoutingKey`三个才能决定一个从`Exchange`到`Queue`的唯一的线路。

![img_13.png](img_13.png)

## RabbitMQ的工作模式

### 一.simple模式（即最简单的收发模式）

![img_14.png](img_14.png)

1. 消息产生消息，将消息放入队列

2. 消息的消费者(`consumer`) 监听消息队列,如果队列中有消息,就消费掉,消息被拿走后,自动从队列中删除(隐患：消息可能没有被消费者正确处理,已经从队列中消失了,造成消息的丢失，
这里可以设置成手动的`ack`,但如果设置成手动`ack`，处理完后要及时发送`ack`消息给队列，否则会造成内存溢出)。

### 二.work工作模式(资源的竞争)

![img_15.png](img_15.png)

1. 消息产生者将消息放入队列消费者可以有多个,消费者1,消费者2同时监听同一个队列,消息被消费。C1 C2共同争抢当前的消息队列内容,谁先拿到谁负责消费消息(隐患：高并发情况下,
默认会产生某一个消息被多个消费者共同使用,可以设置一个开关(`syncronize`) 保证一条消息只能被一个消费者使用)。

### 三.publish/subscribe发布订阅(共享资源)

![img_16.png](img_16.png)

1. 每个消费者监听自己的队列；

2. 生产者将消息发给`broker`，由交换机将消息转发到绑定此交换机的每个队列，每个绑定交换机的队列都将接收到消息。

### 四.routing路由模式

![img_17.png](img_17.png)

1. 消息生产者将消息发送给交换机按照路由判断,路由是字符串(`info`) 当前产生的消息携带路由字符(对象的方法),交换机根据路由的`key,`只能匹配上路由`key`对应的消息队列,对应的消费者才能消费消息;

2. 根据业务功能定义路由字符串

3. 从系统的代码逻辑中获取对应的功能字符串,将消息任务扔到对应的队列中。

4. 业务场景:error 通知;`EXCEPTION`;错误通知的功能;传统意义的错误通知;客户通知;利用key路由,可以将程序中的错误封装成消息传入到消息队列中,开发者可以自定义消费者,实时接收错误;

### 五.topic 主题模式(路由模式的一种)

![img_18.png](img_18.png)

1. 星号井号代表通配符

2. 星号代表多个单词,井号代表一个单词

3. 路由功能添加模糊匹配

4. 消息产生者产生消息,把消息交给交换机

5. 交换机根据`key`的规则模糊匹配到对应的队列,由队列的监听消费者接收消息消费

（在我的理解看来就是`routing`查询的一种模糊匹配，就类似sql的模糊查询方式）

## 如何保证RabbitMQ消息的顺序性？

拆分多个 `queue`，每个 `queue` 一个 `consumer`，就是多一些 `queue` 而已，确实是麻烦点；
或者就一个 `queue` 但是对应一个 `consumer`，然后这个 `consumer` 内部用内存队列做排队，然后分发给底层不同的 `worker` 来处理。

## 消息如何分发？

若该队列至少有一个消费者订阅，消息将以循环（`round-robin`）的方式发送给消费者。每条消息只会分发给一个订阅的消费者（前提是消费者能够正常处理消息并进行确认）。通过路由可实现多消费的功能

## 消息怎么路由？

消息提供方->路由->一至多个队列消息发布到交换器时，消息将拥有一个路由键（`routing key`），在消息创建时设定。通过队列路由键，可以把队列绑定到交换器上。消息到达交换器后，
`RabbitMQ` 会将消息的路由键与队列的路由键进行匹配（针对不同的交换器有不同的路由规则）；

常用的交换器主要分为一下三种：

* **fanout**：如果交换器收到消息，将会广播到所有绑定的队列上

* **direct**：如果路由键完全匹配，消息就被投递到相应的队列

* **topic**：可以使来自不同源头的消息能够到达同一个队列。 使用 `topic` 交换器时，可以使用通配符

## 消息基于什么传输？

由于 `TCP` 连接的创建和销毁开销较大，且并发数受系统资源限制，会造成性能瓶颈。`RabbitMQ` 使用**信道**的方式来传输数据。**信道是建立在真实的 TCP 连接内的虚拟连接**，
且每条 `TCP` 连接上的信道数量没有限制。

## 如何保证消息不被重复消费？或者说，如何保证消息消费时的幂等性？

先说为什么会重复消费：正常情况下，消费者在消费消息的时候，消费完毕后，会发送一个确认消息给消息队列，消息队列就知道该消息被消费了，就会将该消息从消息队列中删除；

但是因为网络传输等等故障，确认信息没有传送到消息队列，导致消息队列不知道自己已经消费过该消息了，再次将消息分发给其他的消费者。

针对以上问题，一个解决思路是：**保证消息的唯一性，就算是多次传输，不要让消息的多次消费带来影响；保证消息等幂性；**

比如：在写入消息队列的数据做唯一标示，消费消息时，根据唯一标识判断是否消费过；

假设你有个系统，消费一条消息就往数据库里插入一条数据，要是你一个消息重复两次，你不就插入了两条，这数据不就错了？但是你要是消费到第二次的时候，自己判断一下是否已经消费过了，
若是就直接扔了，这样不就保留了一条数据，从而保证了数据的正确性。

## 如何确保消息正确地发送至 RabbitMQ？ 如何确保消息接收方消费了消息？

### 发送方确认模式

将信道设置成 `confirm` 模式（发送方确认模式），则所有在信道上发布的消息都会被指派一个唯一的 ID。

一旦消息被投递到目的队列后，或者消息被写入磁盘后（可持久化的消息），信道会发送一个确认给生产者（包含消息唯一 ID）。

如果 `RabbitMQ` 发生内部错误从而导致消息丢失，会发送一条 `nack`（notacknowledged，未确认）消息。

发送方确认模式是异步的，生产者应用程序在等待确认的同时，可以继续发送消息。当确认消息到达生产者应用程序，生产者应用程序的回调方法就会被触发来处理确认消息。

### 接收方确认机制

消费者接收每一条消息后都必须进行确认（消息接收和消息确认是两个不同操作）。只有消费者确认了消息，`RabbitMQ` 才能安全地把消息从队列中删除。

这里并没有用到超时机制，`RabbitMQ` 仅通过 `Consumer` 的连接中断来确认是否需要重新发送消息。也就是说，只要连接不中断，`RabbitMQ` 给了 `Consumer` 足够长的时间来处理消息。
保证数据的最终一致性；

下面罗列几种特殊情况

* 如果消费者接收到消息，在确认之前断开了连接或取消订阅，`RabbitMQ` 会认为消息没有被分发，然后重新分发给下一个订阅的消费者。（可能存在消息重复消费的隐患，需要去重）
* 如果消费者接收到消息却没有确认消息，连接也未断开，则 `RabbitMQ` 认为该消费者繁忙，将不会给该消费者分发更多的消息。

## 如何保证RabbitMQ消息的可靠传输？

消息不可靠的情况可能是消息丢失，劫持等原因；

丢失又分为：**生产者丢失消息**、**消息列表丢失消息**、**消费者丢失消息**；

* **生产者丢失消息**：从生产者弄丢数据这个角度来看，`RabbitMQ`提供`transaction`和`confirm`模式来确保生产者不丢消息；

  1. `transaction`机制就是说：发送消息前，开启事务（`channel.txSelect()`）,然后发送消息，如果发送过程中出现什么异常，事务就会回滚（`channel.txRollback()`）,
  如果发送成功则提交事务（`channel.txCommit()`）。然而，这种方式有个缺点：吞吐量下降； 
  2. `confirm`模式用的居多：一旦`channel`进入`confirm`模式，所有在该信道上发布的消息都将会被指派一个唯一的ID（从1开始），一旦消息被投递到所有匹配的队列之后；
  `rabbitMQ`就会发送一个`ACK`给生产者（包含消息的唯一ID），这就使得生产者知道消息已经正确到达目的队列了；
  如果`rabbitMQ`没能处理该消息，则会发送一个`Nack`消息给你，你可以进行重试操作。

* **消息队列丢数据**：消息持久化。

    处理消息队列丢数据的情况，一般是开启持久化磁盘的配置。这个持久化配置可以和`confirm`机制配合使用，你可以在消息持久化磁盘后，再给生产者发送一个`Ack`信号。这样，如果消息持久化磁盘之前，
    `rabbitMQ`阵亡了，那么生产者收不到`Ack`信号，生产者会自动重发。

    那么如何持久化呢？

    这里顺便说一下吧，其实也很容易，就下面两步:

    1. 将`queue`的持久化标识`durable`设置为`true`,则代表是一个持久的队列
    2. 发送消息的时候将`deliveryMode=2`
  
    这样设置以后，即使`rabbitMQ`挂了，重启后也能恢复数据

* **消费者丢失消息**：消费者丢数据一般是因为采用了自动确认消息模式，改为手动确认消息即可！

    消费者在收到消息之后，处理消息之前，会自动回复`RabbitMQ`已收到消息；
    如果这时处理消息失败，就会丢失该消息；解决方案：处理消息成功后，手动回复确认消息。

## 为什么不应该对所有的 message 都使用持久化机制？

首先，必然导致性能的下降，因为写磁盘比写 `RAM` 慢的多，`message` 的吞吐量可能有 `10` 倍的差距。

其次，`message` 的持久化机制用在 `RabbitMQ` 的内置 `cluster` 方案时会出现“坑爹”问题。矛盾点在于，若 `message` 设置了 `persistent` 属性，但 `queue` 未设置 `durable` 属性，
那么当该 `queue` 的 `owner node` 出现异常后，在未重建该 `queue` 前，发往该 `queue` 的 `message` 将被 `blackholed` ；

若 `message` 设置了 `persistent` 属性，同时 `queue` 也设置了 `durable` 属性，那么当 `queue` 的 `owner node` 异常且无法重启的情况下，则该 `queue` 无法在其他 `node` 上重建，
只能等待其 `owner node` 重启后，才能恢复该 `queue` 的使用，而在这段时间内发送给该 `queue` 的 `message` 将被 `blackholed` 。

所以，是否要对 `message` 进行持久化，需要综合考虑性能需要，以及可能遇到的问题。若想达到 100,000 条/秒以上的消息吞吐量（单 `RabbitMQ` 服务器），
则要么使用其他的方式来确保 `message` 的可靠 `delivery` ，要么使用非常快速的存储系统以支持全持久化（例如使用 `SSD`）。

另外一种处理原则是：**仅对关键消息作持久化处理（根据业务重要程度），且应该保证关键消息的量不会导致性能瓶颈。**

## 如何保证高可用的？RabbitMQ 的集群

`RabbitMQ` 是比较有代表性的，因为是基于主从（非分布式）做高可用性的，我们就以 `RabbitMQ` 为例子讲解第一种 MQ 的高可用性怎么实现。

RabbitMQ 有三种模式：**单机模式**、**普通集群模式**、**镜像集群模式**。

* **单机模式**: 就是 `Demo` 级别的，一般就是你本地启动了玩玩儿的，没人生产用单机模式

* **普通集群模式**: 意思就是在多台机器上启动多个 RabbitMQ 实例，每个机器启动一个。你创建的 `queue`，只会放在一个 RabbitMQ 实例上，
但是每个实例都同步 `queue` 的元数据（元数据可以认为是 `queue` 的一些配置信息，通过元数据，可以找到 `queue` 所在实例）。你消费的时候，实际上如果连接到了另外一个实例，
那么那个实例会从 `queue` 所在实例上拉取数据过来。这方案主要是提高吞吐量的，就是说让集群中多个节点来服务某个 `queue` 的读写操作。

* **镜像集群模式**: 这种模式，才是所谓的 RabbitMQ 的高可用模式。跟普通集群模式不一样的是，在镜像集群模式下，你创建的 `queue`，无论元数据还是 `queue` 里的消息都会存在于多个实例上，
就是说，每个 RabbitMQ 节点都有这个 `queue` 的一个完整镜像，包含 `queue` 的全部数据的意思。然后每次你写消息到 `queue` 的时候，都会自动把消息同步到多个实例的 `queue` 上。
RabbitMQ 有很好的管理控制台，就是在后台新增一个策略，这个策略是镜像集群模式的策略，指定的时候是可以要求数据同步到所有节点的，也可以要求同步到指定数量的节点，再次创建 `queue` 的时候，
应用这个策略，就会自动将数据同步到其他的节点上去了。这样的话，好处在于，你任何一个机器宕机了，没事儿，其它机器（节点）还包含了这个 `queue` 的完整数据，
别的 `consumer` 都可以到其它节点上去消费数据。坏处在于，第一，这个性能开销也太大了吧，消息需要同步到所有机器上，导致网络带宽压力和消耗很重！RabbitMQ 一个 `queue` 的数据都是放在一个节点里的，
镜像集群下，也是每个节点都放这个 `queue` 的完整数据。

## 如何解决消息队列的延时以及过期失效问题？消息队列满了以后该怎么处理？有几百万消息持续积压几小时，说说怎么解决？

**消息积压处理办法：临时紧急扩容**：

先修复 `consumer` 的问题，确保其恢复消费速度，然后将现有 `consumer` 都停掉。

新建一个 `topic`，`partition` 是原来的 10 倍，临时建立好原先 10 倍的 `queue` 数量。

然后写一个临时的分发数据的 `consumer` 程序，这个程序部署上去消费积压的数据，消费之后不做耗时的处理，直接均匀轮询写入临时建立好的 10 倍数量的 `queue`。

接着临时征用 10 倍的机器来部署 `consumer`，每一批 `consumer` 消费一个临时 `queue` 的数据。这种做法相当于是临时将 `queue` 资源和 `consumer` 资源扩大 10 倍，以正常的 10 倍速度来消费数据。
等快速消费完积压数据之后，得恢复原先部署的架构，重新用原先的 consumer 机器来消费消息。

**MQ中消息失效 :**

假设你用的是 RabbitMQ，RabbitMQ 是可以设置过期时间的，也就是 `TTL`。如果消息在 `queue` 中积压超过一定的时间就会被 RabbitMQ 给清理掉，这个数据就没了。

那这就是第二个坑了。这就不是说数据会大量积压在 mq 里，而是大量的数据会直接搞丢。我们可以采取一个方案，就是批量重导，这个我们之前线上也有类似的场景干过。就是大量积压的时候，
我们当时就直接丢弃数据了，然后等过了高峰期以后，比如大家一起喝咖啡熬夜到晚上12点以后，用户都睡觉了。这个时候我们就开始写程序，将丢失的那批数据，
写个临时程序，一点一点的查出来，然后重新灌入 mq 里面去，把白天丢的数据给他补回来。也只能是这样了。假设 1 万个订单积压在 mq 里面，没有处理，其中 1000 个订单都丢了，
你只能手动写程序把那 1000 个订单给查出来，手动发到 mq 里去再补一次。

**mq消息队列块满了 :**

如果消息积压在 mq 里，你很长时间都没有处理掉，此时导致 mq 都快写满了，咋办？这个还有别的办法吗？没有，谁让你第一个方案执行的太慢了，你临时写程序，接入数据来消费，消费一个丢弃一个，
都不要了，快速消费掉所有的消息。然后走第二个方案，到了晚上再补数据吧。
